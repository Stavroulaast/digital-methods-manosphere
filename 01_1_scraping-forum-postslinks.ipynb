{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e004a5c8-3aff-47e9-a1b0-133c80229a7f",
   "metadata": {},
   "source": [
    "### Data collection - Scraping FORUMS.RED posts \n",
    "\n",
    "This notebook includes the code used for scraping posts from FORUMS.RED \"What's Hot\" page, sorted by new posts and filtered by ‚Äùall-time‚Äù time frame. \n",
    "\n",
    "This approach allowed us to collect data from a topic-restricted, semi-bounded population. Our approach aligns with the logic of trawling, defined as the systematic collection of already-published online content. In practice, this meant scraping six years of historical forum content rather than tracking real-time user behaviour beginning from the start of the project forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907fe6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping\n",
    "import requests\n",
    "import urllib.parse\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Timing and randomness\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Progress display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2bd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json #For saving intermediate data \n",
    "import pandas as pd #for working with structured datasets\n",
    "import numpy as np #for numerical computations\n",
    "import datetime  # For handling date/time conversions and computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4278c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "\n",
    "languages = [\n",
    "    'en-US,en;q=0.9',\n",
    "    'en-GB,en;q=0.8',\n",
    "    'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'es-ES,es;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'it-IT,it;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a19a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    user_agent = ua.random\n",
    "    accept_language = random.choice(languages)\n",
    "\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(f\"--user-agent={user_agent}\")\n",
    "    options.add_argument(f\"--lang={accept_language}\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--headless=chrome\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2803eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_alltime_forum_url(url=\"https://www.forums.red/i/?sort=2&timeframe=1\", delay=5, max_waits=5):\n",
    "    post_links = []\n",
    "    seen_links = set()\n",
    "    scroll_count = 0\n",
    "    partial_csv = \"forums_alltime_links_partial.csv\"\n",
    "    final_csv = \"forums_alltime_links_final.csv\"\n",
    "\n",
    "    # Load previously saved links (resume support)\n",
    "    if os.path.exists(partial_csv):\n",
    "        df_existing = pd.read_csv(partial_csv)\n",
    "        seen_links = set(df_existing[\"url\"].tolist())\n",
    "        post_links = list(seen_links)\n",
    "        print(f\"üîÅ Resuming from saved file: {len(post_links)} links already scraped.\")\n",
    "\n",
    "    try:\n",
    "        driver = get_driver()\n",
    "        driver.get(url)\n",
    "        time.sleep(delay)\n",
    "\n",
    "        print(f\"üîΩ Scrolling until end of URL: {url}\")\n",
    "\n",
    "        with tqdm(desc=\"Scrolling forum\", unit=\"scroll\") as pbar:\n",
    "            prev_links_count = len(seen_links)\n",
    "            stale_scrolls = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    # Check if browser is still alive\n",
    "                    _ = driver.title\n",
    "\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(delay + random.uniform(1.0, 2.0))\n",
    "\n",
    "                    anchors = driver.find_elements(By.XPATH, \"//a[text()='Permalink']\")\n",
    "                    new_links_found = False\n",
    "\n",
    "                    for a in anchors:\n",
    "                        href = a.get_attribute(\"href\")\n",
    "                        if href and href not in seen_links:\n",
    "                            seen_links.add(href)\n",
    "                            post_links.append(href)\n",
    "                            new_links_found = True\n",
    "\n",
    "                    scroll_count += 1\n",
    "\n",
    "                    if not new_links_found:\n",
    "                        stale_scrolls += 1\n",
    "                    else:\n",
    "                        stale_scrolls = 0\n",
    "\n",
    "                    if stale_scrolls >= max_waits:\n",
    "                        print(\"‚è∏Ô∏è No new posts loaded for several scrolls ‚Äî stopping.\")\n",
    "                        break\n",
    "\n",
    "                    # Autosave every 10 scrolls\n",
    "                    if scroll_count % 10 == 0:\n",
    "                        pd.DataFrame(post_links, columns=[\"url\"]).to_csv(partial_csv, index=False)\n",
    "                        print(f\"üíæ Autosaved {len(post_links)} links at scroll {scroll_count}\")\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Scroll failed: {e}\")\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during scraping: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Final save\n",
    "    df = pd.DataFrame(post_links, columns=[\"url\"])\n",
    "    df.to_csv(final_csv, index=False)\n",
    "    print(f\"‚úÖ Final CSV saved: {final_csv} ({len(df)} links)\")\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltime_links = scrape_alltime_forum_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e995cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('forums_alltime_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9031f37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.forums.red/p/asktrp/324046/girl_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.forums.red/p/asktrp/324045/anyone_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.forums.red/p/asktrp/324044/plate_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.forums.red/p/asktrp/324043/what_do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.forums.red/p/asktrp/324041/how_to_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18149</th>\n",
       "      <td>https://www.forums.red/p/asktrp/209528/questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18150</th>\n",
       "      <td>https://www.forums.red/p/asktrp/209527/thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>https://www.forums.red/p/asktrp/209526/guys_25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>https://www.forums.red/p/asktrp/209525/how_muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>https://www.forums.red/p/asktrp/209590/girl_sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18154 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url\n",
       "0      https://www.forums.red/p/asktrp/324046/girl_di...\n",
       "1      https://www.forums.red/p/asktrp/324045/anyone_...\n",
       "2      https://www.forums.red/p/asktrp/324044/plate_a...\n",
       "3      https://www.forums.red/p/asktrp/324043/what_do...\n",
       "4      https://www.forums.red/p/asktrp/324041/how_to_...\n",
       "...                                                  ...\n",
       "18149  https://www.forums.red/p/asktrp/209528/questio...\n",
       "18150  https://www.forums.red/p/asktrp/209527/thought...\n",
       "18151  https://www.forums.red/p/asktrp/209526/guys_25...\n",
       "18152  https://www.forums.red/p/asktrp/209525/how_muc...\n",
       "18153  https://www.forums.red/p/asktrp/209590/girl_sa...\n",
       "\n",
       "[18154 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96496c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
